# Web Scraping with Python #

## What is Web Scraping? ##
Web Scraping (auch Web Data Mining oder Web Harvesting genannt) bezeichnet den Prozess, Daten aus dem Internet automatisiert zu extrahieren, aufzubereiten und zu analysieren. Die Praktik gehört damit in den Bereich der Data Science, genauer des Data Minings. Web Scraping ist ein idealer Einstiegspunkt für Anfänger, um zu verstehen, wie man mit der schier unendlichen Datenflut im Netz umgehen kann.
https://bmu-verlag.de/webscraping-mit-python/

Web scraping is an automated method used to extract large amounts of data from websites. The data on the websites are unstructured. Web scraping helps collect these unstructured data and store it in a structured form. There are different ways to scrape websites such as online Services, APIs or writing your own code.
Talking about whether web scraping is legal or not, some websites allow web scraping and some don’t. To know whether a website allows web scraping or not, you can look at the website’s “robots.txt” file. You can find this file by appending “/robots.txt” to the URL that you want to scrape. For this example, I am scraping Flipkart website. So, to see the “robots.txt” file, the URL is www.flipkart.com/robots.txt.
https://www.edureka.co/blog/web-scraping-with-python/

## Which tools can we use? ##
- Beautiful Soup
  https://beautiful-soup-4.readthedocs.io/en/latest/
  Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree.

- pandas
  https://pandas.pydata.org/
  pandas is a fast, powerful, flexible and easy to use open-source data analysis and manipulation tool, built on top of the Python programming language.

- requests
  https://requests.readthedocs.io/en/master/
  Requests is an elegant and simple HTTP library for Python, built for human beings. Requests allows you to send HTTP/1.1 requests extremely easily. There's no need to manually add query strings to your URLs, or to form-encode your POST data. Keep-alive and HTTP connection pooling are 100% automatic, thanks to urllib3.

- Selenium
  https://www.selenium.dev/
  Selenium is an umbrella project for a range of tools and libraries that enable and support the automation of web browsers. 
  It provides extensions to emulate user interaction with browsers, a distribution server for scaling browser allocation, and the infrastructure for implementations of the W3C WebDriver specification that lets you write interchangeable code for all major web browsers.

